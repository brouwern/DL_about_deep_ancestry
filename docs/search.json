[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Deep Learning about deep ancestry",
    "section": "",
    "text": "Nathan L. Brouwer, PhD"
  },
  {
    "objectID": "index.html#consumer-genomics-data",
    "href": "index.html#consumer-genomics-data",
    "title": "Deep Learning about deep ancestry",
    "section": "üß¨ Consumer genomics data",
    "text": "üß¨ Consumer genomics data\nDirect-to-consumer genomic testing services typically provide a thorough set of results, as well as access to your own raw data. While the reports provided by companies can be very flashy, the raw data for a single person is rather under-whelming, as we can see when its loaded into Python:\n\n\n\n\n\n\n\n\n\n# rsid\nchromosome\nposition\ngenotype\n\n\n\n\n0\nrs10034228\n4\n112611750\nCC\n\n\n1\nrs560766\n15\n35000942\nGG\n\n\n2\nrs939661\n15\n79431063\nAG\n\n\n\n\n\n\n\nThis small snapshot of data is froom 23andMe, but is similar to genomic data from other services as well as that produced by researchers. Each row of these data represent a position in the human genomes where people frequently vary from each other, with the genotype indicating what the sequence is for the person‚Äôs DNA being examined. Two letters are shown, one for each of the person‚Äôs parents. ‚ÄúCC‚Äù in the top row means that for this place in the genome, the person recieved a ‚ÄúC‚Äù DNA base from both parents. In contrast, the ‚ÄúAGs‚Äù on the third row indicates that they inherited an ‚ÄúA‚Äù DNA base from one parent and a ‚ÄúG‚Äù from the other. For any given row there are 3 possible combinations of letters that can occur in differnet people. For example, for the AG row, somewhere in the world there are poeple who are AA and others who are GG.\nTo carry out genomic analyses, these data have to be converted to numbers. For our analysis, we‚Äôll use a simple number system where each of the three combinations that can occur on a row are coded 0, 1 or 2. In the case of the AG rows, ‚ÄúAG‚Äù would be coded as an intermediate value of 1, while AA and GG would be coded as 0 and 2. This results in our snapshot of data looking like this:\n\n\n\n\n\n\n\n\n\n# rsid\nchromosome\nposition\ngenotype\n\n\n\n\n0\nrs10034228\n4\n112611750\n2\n\n\n1\nrs560766\n15\n35000942\n0\n\n\n2\nrs939661\n15\n79431063\n1\n\n\n\n\n\n\n\nIt is important to point out that genomic data is truly ‚Äúbig data‚Äù. For example, data from 23andMe for one person contains over 900,000 rows! This may seem huge, but its actually less than 0.05% of the size of the human genome."
  },
  {
    "objectID": "index.html#population-genomics-data",
    "href": "index.html#population-genomics-data",
    "title": "Deep Learning about deep ancestry",
    "section": "üåç Population genomics data",
    "text": "üåç Population genomics data\nIn order to characterize someone‚Äôs ancestry we must have a database of many people from around the world to compare them too. While consumer genomics companies have compiled their extensive but proprietery databases, there are also open-access datasets available for anyone to use. The largest public database is the 1000 Genomes Project (1KGP), which contains genomic information on ~2500 people from 25 populations around the world. 1KGP data has been used in hundreds of scientific papers and can be accessed freely by anyone.\nUnfortunately, 1KGP data is a bit unwieldly to access without specialized software; luckily, subsets of the data have been posted by some researchers. In this artile, I‚Äôll use data provided by researchers from the University of Utah. This study, led by Jinchuan Xing and Lynn Jorde, integrated data from the 1000 Genomes Project with data from Jorde‚Äôs lab, resulting in a database of genomic data with 850 people from 40 different populations. For each person in the dataset, they had genomic data similar to that shown above from 23andMe.\nAfter being prepared for analysis, the data from 5 people for 5 places in their genomes would look like the table below. Each person is in a column, and each row contains a number representing their original DNA sequence. In total, Xing and Jorde‚Äôs study. If two people have many of the same values accross the rows, then they are possiblly from the same or similar populations.\n\n\n\n\n\n\n\n\nUID\nperson01\nperson02\nperson03\nperson04\nperson05\n\n\n\n\nrs6680471\n-0.8\n-0.8\n-0.8\n-0.8\n0.6\n\n\nrs3737593\n1.6\n-0.5\n-0.5\n3.6\n-0.5\n\n\nrs10915495\n-0.6\n0.8\n0.8\n0.8\n2.3\n\n\nrs639739\n1.0\n2.6\n1.0\n-0.6\n-0.6\n\n\nrs780587\n1.5\n1.5\n-0.5\n-0.5\n3.6"
  },
  {
    "objectID": "index.html#machine-learning-and-genomics",
    "href": "index.html#machine-learning-and-genomics",
    "title": "Deep Learning about deep ancestry",
    "section": "ü§ñ Machine learning and genomics",
    "text": "ü§ñ Machine learning and genomics\nMost machine learning models have applications in population genomics, including dimension reduction, clustering, and supervised classification. Biologists interested in human evolutionar are particularly exploring how Deep Learning methods can reveal insights into human history. While the methods used by consumer genomics companies and researchers are complex and tailored to the complexities of genomic data, we can use ‚Äúoff-the-shelf‚Äù tools from data science and machine learning to understand how more advanced models reach their conclusions.\nRegardless of methods, we face two challenges when analyzing genomic data. First, there‚Äôs typically lots of data, with information on hundreds of peole from thousands of places in the genome. Second, each place in the genome serves as a feature (aka variable) of our analysis. In the previous table there were 5 rows and therefore 5 locations in the genome represented. The full dataset has over 10,000 rows.\n\nGoing the distance with DNA\nHow do you analyze data with 10,000 features, let alone make a plot representing the data? Analysis of such high-dimensinal data typically requires methods to represent the data in a simpler format, a process known as dimension reduction. One of the easiest method of dimension reduction is to calculate distance between each datapoint. In geometry class we learn to use the Pythagorean Formula to calculate the distance between two points on a sheet of paper. If we had a cruel teacher, we may have had to extend the formula to three dimensions. It turns out that ‚Äì while we can‚Äôt necessarily visualize how it works ‚Äì this formula can be extended beyond three dimensions to four, five, or even 10,000. We can similarly extend what we know about the average of a set of numbers and consider the multidimensional mean of a set of data.\nThe table below uses this logic to represent the average genetic distance between indvidiauls in major continental groups in Xing and Jorde‚Äôs dataset. First, the average genetic location of people from each continent is determined, and then the distnance between these mean locations calculate.\nThe largest value in the table is 107 in the Africa-Indigenous Americans rows and columns. The populations of these continents are geographically most distant, and genetically they are, relatively speaking, least similar or ‚Äúmost distant.‚Äù (It is very important add the caveat ‚Äúrelatively‚Äù because two humans are typically 98% the same in terms of DNA, and these numers focus only on the infrequent genetic differenes).\nThe smallest value on the table is 52, between Europe and Asia. These two continents are geographically contiguous with each other and their populations have remained the most genetically similar (least distant) depsite lignuistic and cultural change.\n\n\n\n\n\n\n\n\n\nAfrica\nIndigenous Americans\nAsia\nEurope\n\n\nContinental Group\n\n\n\n\n\n\n\n\nAfrica\n0.0\n107.0\n86.0\n90.0\n\n\nIndigenous Americans\n107.0\n0.0\n63.0\n79.0\n\n\nAsia\n86.0\n63.0\n0.0\n52.0\n\n\nEurope\n90.0\n79.0\n52.0\n0.0\n\n\n\n\n\n\n\nOnce we have characterized the similarities and differences between populations, we can take an individual person‚Äôs DNA sample and compare it to the average locations of each continent. I did this for the DNA sample I introduced at the beginning of this article, and the smallest value is for Europe. This indicats that they are least distant and therefore most similar to the other people in the dataset from this continent.\n\n\n\n\n\n\n\n\n\nDistance\n\n\nContinental Group\n\n\n\n\n\nAfrica\n149.0\n\n\nIndigenous Americans\n143.0\n\n\nAsia\n130.0\n\n\nEurope\n118.0\n\n\n\n\n\n\n\n\n\nA picture is worth 10,000 genome locations\nBecause it has so many features, genomic data cannot be plotted using standard tools like scatterplots. Once we have a table of genetic distances, though, we can make a plot using the results of a process called NMDS (Non-metric Multi-Dimensonal Scaling).\nNMDS turns a distance matrix into a set of x-y coordinates that preserves the relative distances between all sets of points. In the plots\n\n\n\n\n\nRelative genetic distances between populations from major continents. Non-metri multi-dimensional scaling was carried out on a matrix of Euclidean distances\n\n\n\n\nThere are many machine learning techniques that can be used to visualize high-dimensional genomics data. One of the most common tools used traditionally in population genomics is Principal Components Analysis (PCA). PCA is an unsupervised machine learning method which allows high-dimensonal data to be visualized in 2 or 3 dimensions. PCA scatterplots with 2 dimensions are called biplots, while those with 3 dimensions are triplots.\nIn the case of genomic data, information on individual DNA samples enters into the PCA and the lower dimensional data is then plotted. Dat points represent individuals people in the sample, and the points are color-coded based on the geographic location where the individuals are from. This allows PCA to serve as both a visualization and clustering approach.\nAdditionally, someone whose ancestry is not known or uncertain can have their data transformed by the PCA and plotted along with the other points. The location of the prediction relative to other data points indicates genetic similarity and potentially similar ancestry.\nThe figure below shows data from Xing and Jorde study discussed above after it has been processed through PCA. The data are color-coded by the large-scale geographic areas the samples are derived from. I then took a 23andMe record for a person with unknown ancestry and used my PCA model to estimate which samples from Xing this person is most similar to. Based on their location, they are most likely predominantly European ancestry.\n\n\n\n\n\nPrincipal Components Analysis (PCA) biplot showing the location (X) of a sample with uncertain ancestry. Based on its location, it can be inferred that this person is likely to be of predominantly European ancestry."
  },
  {
    "objectID": "index.html#ancestry-predictions",
    "href": "index.html#ancestry-predictions",
    "title": "Deep Learning about deep ancestry",
    "section": "üìä Ancestry predictions",
    "text": "üìä Ancestry predictions\nPCA biplots are ubiquitous in scientific papers on population genomics and ancestry, often as a central figure. Consumer genetic companies, however, typically focus their results on assignment to one or more ancestry categories. We can carry out a similar assignment, known technically a multi-class classification, using standard tools in Python. In this Analysis, used a Random-forests classifier to gauge the relative probability that the person‚Äô whose DNA sequence we‚Äôve been working with fit into 1 of 7 possible geographic groups.\n\n\n\n\n\nExamples predictions of geographic ancestry. Predictions were made with a multi-class random forests classifier in scikit-learn."
  },
  {
    "objectID": "index.html#delving-deeper-into-ancestry-and-machine-learning",
    "href": "index.html#delving-deeper-into-ancestry-and-machine-learning",
    "title": "Deep Learning about deep ancestry",
    "section": "Delving deeper into ancestry and machine learning",
    "text": "Delving deeper into ancestry and machine learning\nThe data and analyzes presented in this article should give you a sense for how consumer genomics companies are able to transform a sample of spit or cheek cells into a prediction about someone‚Äôs ancestry. Companies like 23andMe and Ancestry.com now how millions of people in their databases, reference samples from dozens of populations, and machine-learning and deep-learning algorithms tailored to their specific goals. Similar predictions about a person‚Äôs ancestry can be reached using standard machine learning tools. This makes genomic data an excellent place for data scientists explore and test different methods."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to ‚ÄúDeep Learning about deep ancestry‚Äù. This website introduces you to the basics of how DNA sequences and machine learning can be used to characterize someone‚Äôs ancestry. The main landing page of the site contains a high-level overview, while additional sections of the site delve into how genomic data is processed and the machine learning algorithms use."
  },
  {
    "objectID": "about.html#data-sources",
    "href": "about.html#data-sources",
    "title": "About",
    "section": "Data Sources",
    "text": "Data Sources\nThese analyses rely on data from the 1000 Genomes Project (1KGP). The data provided by the ~2500 volunteers from throughout the world to the project 1KGP has been foundational to population genomics. In these articles, I use 1KGP data that was augumented with additional samples by Xing, Jorde, and colleagues in their 2010 paper ‚ÄúToward a more uniform sampling of human genetic diversity: a survey of worldwide populations by high-density genotyping‚Äù, who have generously posted their entire dataset online."
  },
  {
    "objectID": "about.html#previous-presentations",
    "href": "about.html#previous-presentations",
    "title": "About",
    "section": "Previous presentations",
    "text": "Previous presentations\nThese articles are based on material from a course I taught at the University of Pittsburgh from 2020 to 2023, and a presentation at PyOhio 2024.\n\nIf you have any questions, please contact me at brouwern at gmail.com or message me on LinkedIn. Code is available on GitHub."
  },
  {
    "objectID": "genome_size_intro.html",
    "href": "genome_size_intro.html",
    "title": "Tutorial: How big is a genome? Exploring size and scope of the human genome in Python",
    "section": "",
    "text": "This tutorial uses basic libraries in Python to explore how big the human genome is and the volume of data generate when we submit a sample to a genetic testing service like 23andMe."
  },
  {
    "objectID": "genome_size_intro.html#introduction",
    "href": "genome_size_intro.html#introduction",
    "title": "Tutorial: How big is a genome? Exploring size and scope of the human genome in Python",
    "section": "",
    "text": "This tutorial uses basic libraries in Python to explore how big the human genome is and the volume of data generate when we submit a sample to a genetic testing service like 23andMe."
  },
  {
    "objectID": "genome_size_intro.html#preliminaries",
    "href": "genome_size_intro.html#preliminaries",
    "title": "Tutorial: How big is a genome? Exploring size and scope of the human genome in Python",
    "section": "Preliminaries",
    "text": "Preliminaries\n\nLibraries\nWe‚Äôll use standard Python data science libraries in this tutorial, including pandas, seaborn, and numpy.\n\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n\n\n\nData\nThe main dataset in this tutorial is a table of chromosome lengths from the NCBI.\nThis is a small dataset, so we can quickly build a pandas dataframe from the data:\n\n# raw data lists\nchromo_numeric = [1,2,3,4,5,6,7,8,9,10,\n                  11,12,13,14,15,16,17,\n                  18,19,20,21,22,23,24,25]\nchromo_str = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\n                  \"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\n                  \"18\",\"19\",\"20\",\"21\",\"22\",\"X\",\"Y\",\"Mito\"]\nchromo_len = [249250621,243199373,198022430,191154276,180915260,\n                171115067,159138663,146364022,141213431,135534747,135006516,\n                133851895,115169878,107349540,102531392,90354753,81195210,78077248,59128983,\n                63025520,48129895,51304566,155270560,59373566,16569]\n\n# convert to series\nchromo_numeric_ser = pd.Series(chromo_numeric)\nchromo_str_ser = pd.Series(chromo_str)\nchromo_len_ser    = pd.Series(chromo_len)\n\n## additional info\nsnps_approx = chromo_len_ser*0.04\n#chromo_type = [\"Autosome\",\"Sex\",\"Organelle\"]\n#chromo_type = np.repeat(chrom_type, [22,2,1], axis=0)\n#chromo_type_ser = pd.Series(chromo_type)\n\n## build pandas dataframe\nchromo_info = pd.DataFrame({\"chrom_numeric\": chromo_numeric_ser,\n                           \"chromo_str\": chromo_str_ser,\n                           #\"chrom_type\": chromo_type_ser,\n                           \"chrom_len\":   chromo_len_ser,\n                           \"snps_approx\": snps_approx})\n\nThe assembled data looks like this:\n\nchromo_info\n\n\n\n\n\n\n\n\nchrom_numeric\nchromo_str\nchrom_len\nsnps_approx\n\n\n\n\n0\n1\n1\n249250621\n9970024.84\n\n\n1\n2\n2\n243199373\n9727974.92\n\n\n2\n3\n3\n198022430\n7920897.20\n\n\n3\n4\n4\n191154276\n7646171.04\n\n\n4\n5\n5\n180915260\n7236610.40\n\n\n5\n6\n6\n171115067\n6844602.68\n\n\n6\n7\n7\n159138663\n6365546.52\n\n\n7\n8\n8\n146364022\n5854560.88\n\n\n8\n9\n9\n141213431\n5648537.24\n\n\n9\n10\n10\n135534747\n5421389.88\n\n\n10\n11\n11\n135006516\n5400260.64\n\n\n11\n12\n12\n133851895\n5354075.80\n\n\n12\n13\n13\n115169878\n4606795.12\n\n\n13\n14\n14\n107349540\n4293981.60\n\n\n14\n15\n15\n102531392\n4101255.68\n\n\n15\n16\n16\n90354753\n3614190.12\n\n\n16\n17\n17\n81195210\n3247808.40\n\n\n17\n18\n18\n78077248\n3123089.92\n\n\n18\n19\n19\n59128983\n2365159.32\n\n\n19\n20\n20\n63025520\n2521020.80\n\n\n20\n21\n21\n48129895\n1925195.80\n\n\n21\n22\n22\n51304566\n2052182.64\n\n\n22\n23\nX\n155270560\n6210822.40\n\n\n23\n24\nY\n59373566\n2374942.64\n\n\n24\n25\nMito\n16569\n662.76"
  },
  {
    "objectID": "genome_size_intro.html#data-visualization",
    "href": "genome_size_intro.html#data-visualization",
    "title": "Tutorial: How big is a genome? Exploring size and scope of the human genome in Python",
    "section": "Data visualization",
    "text": "Data visualization\n\nChromosome size\n\nsns.barplot(data = chromo_info,\n                x = \"chrom_len\",\n                y = \"chrom_numeric\",\n                orient = 'h'#,\n                #hue = \"chrom_type\"\n                );\n\n\n\n\n\n\n\n\n\n\nHow much of human genome is examined by 23andMe?\nCalculations\n\ntotal = chromo_len_ser.sum()\nsnps_23_and_me = 929045 # from 1117.23andme.txt\nother = total -snps_23_and_me\nsnps_percent = snps_23_and_me/total*100\nprint(\"Approximately\", round(snps_percent,3), \"percent of our genome is represented in data from 23andMe\")\n\nApproximately 0.03 percent of our genome is represented in data from 23andMe\n\n\nPiegraph\n\nplt.close()\nplt.pie([snps_23_and_me,other],\n labels=[\"23andme\\nPositions\",\"Rest of\\ngenome\"]) ;\n\n\n\n\n\n\n\n\nHow much of our genome is examined in research-grade datasets?\n\ngenomes1k = 125484020 # Byrska-Bishop et al 2022\nother = total -genomes1k\nsnps_1kgpercent = genomes1k/total*100\n\nPie graph\n\nplt.close()\nplt.pie([genomes1k,other],\n labels=[\"1000 Genomes\\nProject\",\"Rest of\\ngenome\"]) ;\n\n\n\n\n\n\n\n\n\n\nChromosome size versus amount survey\n\nplt.close()\nbar1 = sns.barplot(data = chromo_info,\nx = \"chrom_len\",\ny = \"chrom_numeric\",\norient = 'h'#,\n    #hue = \"chrom_type\"\n    );\n\nbar2 = sns.barplot(x=\"snps_approx\", y=\"chrom_numeric\", data = chromo_info,color='lightblue',orient = 'h');\n\ntop_bar = mpatches.Patch(color='darkblue', label='x')\nbottom_bar = mpatches.Patch(color='lightblue', label='y')\n\n\nplt.show()"
  },
  {
    "objectID": "genome_size_intro.html#size-of-consumer-genomics-industry",
    "href": "genome_size_intro.html#size-of-consumer-genomics-industry",
    "title": "Tutorial: How big is a genome? Exploring size and scope of the human genome in Python",
    "section": "Size of consumer genomics industry",
    "text": "Size of consumer genomics industry\nTODO: data source\n\nmil = 1000000\nplt.close()\nN = [25000000/mil,14000000/mil,8000000/mil,1628438/mil,300000/mil]\ncompany = [\"Ancestry.com\",\"23andMe\",\"MyHeritage\",\"Family Tree DNA\\nFamily Finder\",\"Living DNA\"]\n\ndf = pd.DataFrame({\"DNA tests (millions)\": N,\n                    \"Company\": company})\n\nsns.barplot(data = df,y = \"DNA tests (millions)\", x = \"Company\")\n\n\n\n\n\n\n\n\n\nplt.close()\n# library\nimport matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2\n# 949904\n# 246554\n# Use the venn2 function\nvenn2(subsets = (950000-250000-72000, 250000-72000, 72000), set_labels = ('23andMe', 'Xing et al. 2010'))\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.close()\nfrom matplotlib_venn import venn2\nvenn2(subsets = (3, 2, 1))\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.close()\nfrom matplotlib_venn import venn3\nvenn3(subsets = (0, 0, 72000,  # 1, 2, 1 vs 2\n                 125000000-950000-250000-72000, 950000-72000, 250000-72000,  # 3, 3 vs 1, 3 vs 2\n                 72000),       # all shared\n                 set_labels = ('Set1', 'Set2', 'Set3'))\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.close()\nfrom matplotlib import pyplot as plt\nimport numpy as np\nfrom matplotlib_venn import venn3, venn3_circles\nplt.figure(figsize=(4,4))\nv = venn3(subsets=(125000000, 950000, 250000, \n                   950000, 250000, 1, \n                   1), \n          set_labels = ('A', 'B', 'C'))\nv.get_patch_by_id('100').set_alpha(1.0)\nv.get_patch_by_id('100').set_color('white')\nv.get_label_by_id('100').set_text('Unknown')\nv.get_label_by_id('A').set_text('Set \"A\"')\nc = venn3_circles(subsets=(1, 1, 1, 1, 1, 1, 1), linestyle='dashed')\nc[0].set_lw(1.0)\nc[0].set_ls('dotted')\nplt.title(\"Sample Venn diagram\")\nplt.annotate('Unknown set', xy=v.get_label_by_id('100').get_position() - np.array([0, 0.05]), xytext=(-70,-70),\n             ha='center', textcoords='offset points', bbox=dict(boxstyle='round,pad=0.5', fc='gray', alpha=0.1),\n             arrowprops=dict(arrowstyle='-&gt;', connectionstyle='arc3,rad=0.5',color='gray'))\nplt.show()"
  }
]