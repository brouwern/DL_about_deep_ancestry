[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Deep Learning about deep ancestry",
    "section": "",
    "text": "Nathan L. Brouwer, PhD"
  },
  {
    "objectID": "index.html#genetic-testing-services-use-a-combination-of-advanced-dna-sequencing-and-machine-learning-to-characterize-a-persons-deep-heritage",
    "href": "index.html#genetic-testing-services-use-a-combination-of-advanced-dna-sequencing-and-machine-learning-to-characterize-a-persons-deep-heritage",
    "title": "Deep Learning about deep ancestry",
    "section": "Genetic testing services use a combination of advanced DNA sequencing and machine learning to characterize a person‚Äôs deep heritage",
    "text": "Genetic testing services use a combination of advanced DNA sequencing and machine learning to characterize a person‚Äôs deep heritage\nIn the last 20 years, using DNA to charaterize people‚Äôs ancestry has become a multi-billion dollar industry, with millions of American‚Äôs having had their genomes sequenced by ancestry services like 23andMe and Ancestry.com. People now routinely contemplate results like those in the table below, with their family‚Äôs history rendered with apparent mathematical precision. But how exactly can a small sample of cells in a test-tube be converted to numbers that somehow represent people‚Äôs heritage, ancestry, and parentage?\n\n\n\n\n\nSample predictions of geographic ancestry\n\n\n\n\nThe technology that makes modern genomic ancestry assessment possible is a combination from multiple fields, including advanced DNA sequencing, genome science, and machine learning. While you can‚Äôt sequence your own genome (yet), it takes only a moderate amount of computer programming skills and some open-access data to see how companies like 23andMe and Ancestry.com do their magic.\nIn this article I will Python to\n\nüß¨ Briefly explains what raw genomic testing data looks like\nüåç Introduce the types of population-scale genome data needed to understand human ancestry\nü§ñ Give an overview of machine learning models used in genomics\nüìä Show how a person‚Äôs ancestry can be predicted using a machine-learning model\n\nAdditional articles will present more in depth how these data are processed and results created."
  },
  {
    "objectID": "index.html#consumer-genomics-data",
    "href": "index.html#consumer-genomics-data",
    "title": "Deep Learning about deep ancestry",
    "section": "üß¨ Consumer genomics data",
    "text": "üß¨ Consumer genomics data\nDirect-to-consumer genomic testing services typically provide a thorough set of results, as well as access to your own raw data. While the reports provided by companies can be very flashy, the raw data for a single person is rather under-whelming, as we can see when its loaded into Python:\n\n\n\n\n\n\n\n\n\n# rsid\nchromosome\nposition\ngenotype\n\n\n\n\n0\nrs10034228\n4\n112611750\nCC\n\n\n1\nrs560766\n15\n35000942\nGG\n\n\n2\nrs939661\n15\n79431063\nAG\n\n\n\n\n\n\n\nThis small snapshot of data is froom 23andMe, but is similar to genomic data from other services as well as that produced by researchers. Each row of these data represent a position in the human genomes where people frequently vary from each other, with the genotype indicating what the sequence is for the person‚Äôs DNA being examined. Two letters are shown, one for each of the person‚Äôs parents. ‚ÄúCC‚Äù in the top row means that for this place in the genome, the person recieved a ‚ÄúC‚Äù DNA base from both parents. In contrast, the ‚ÄúAGs‚Äù on the third row indicates that they inherited an ‚ÄúA‚Äù DNA base from one parent and a ‚ÄúG‚Äù from the other. For any given row there are 3 possible combinations of letters that can occur in differnet people. For example, for the AG row, somewhere in the world there are poeple who are AA and others who are GG.\n\n#temp = pd.concat([genos4.iloc[:,0],continents], axis = 1)\n\n#temp.rs6680471[temp.rs6680471 == temp.rs6680471.min()] = 0\n#temp.rs6680471[temp.rs6680471 == temp.rs6680471.max()] = 2\n#temp.rs6680471[temp.rs6680471.round(2) == 0.64] = 1\n\n#temp.value_counts()\n#pd.pivot_table(temp, \n#               index = \"Continental Group\", \n#               values = \"rs6680471\",\n#               columns = \"rs6680471\",\n#               aggfunc = \"sum\")\n\nTo carry out genomic analyses, these data have to be converted to numbers. For our analysis, we‚Äôll use a simple number system where each of the three combinations that can occur on a row are coded 0, 1 or 2. In the case of the AG rows, ‚ÄúAG‚Äù would be coded as an intermediate value of 1, while AA and GG would be coded as 0 and 2. This results in our snapshot of data looking like this:\n\n\n\n\n\n\n\n\n\n# rsid\nchromosome\nposition\ngenotype\n\n\n\n\n0\nrs10034228\n4\n112611750\n2\n\n\n1\nrs560766\n15\n35000942\n0\n\n\n2\nrs939661\n15\n79431063\n1\n\n\n\n\n\n\n\nIt is important to point out that genomic data is truly ‚Äúbig data‚Äù. For example, data from 23andMe for one person contains over 900,000 rows! This may seem huge, but its actually less than 0.05% of the size of the human genome."
  },
  {
    "objectID": "index.html#population-genomics-data",
    "href": "index.html#population-genomics-data",
    "title": "Deep Learning about deep ancestry",
    "section": "üåç Population genomics data",
    "text": "üåç Population genomics data\nIn order to characterize someone‚Äôs ancestry we must have a database of many people from around the world to compare them too. While consumer genomics companies have compiled their extensive but proprietery databases, there are also open-access datasets available for anyone to use. The largest public database is the 1000 Genomes Project (1KGP), which contains genomic information on ~2500 people from 25 populations around the world. 1KGP data has been used in hundreds of scientific papers and can be accessed freely by anyone.\nUnfortunately, 1KGP data is a bit unwieldly to access without specialized software; luckily, subsets of the data have been posted by some researchers. In this artile, I‚Äôll use data provided by researchers from the University of Utah. This study, led by Jinchuan Xing and Lynn Jorde, integrated data from the 1000 Genomes Project with data from Jorde‚Äôs lab, resulting in a database of genomic data with 850 people from 40 different populations. For each person in the dataset, they had genomic data similar to that shown above from 23andMe.\nAfter being prepared for analysis, the data from 5 people for 5 places in their genomes would look like the table below. Each person is in a column, and each row contains a number representing their original DNA sequence. In total, Xing and Jorde‚Äôs study. If two people have many of the same values accross the rows, then they are possiblly from the same or similar populations.\n\n\n\n\n\n\n\n\nUID\nperson01\nperson02\nperson03\nperson04\nperson05\n\n\n\n\nrs6680471\n-0.8\n-0.8\n-0.8\n-0.8\n0.6\n\n\nrs3737593\n1.6\n-0.5\n-0.5\n3.6\n-0.5\n\n\nrs10915495\n-0.6\n0.8\n0.8\n0.8\n2.3\n\n\nrs639739\n1.0\n2.6\n1.0\n-0.6\n-0.6\n\n\nrs780587\n1.5\n1.5\n-0.5\n-0.5\n3.6"
  },
  {
    "objectID": "index.html#machine-learning-and-genomics",
    "href": "index.html#machine-learning-and-genomics",
    "title": "Deep Learning about deep ancestry",
    "section": "ü§ñ Machine learning and genomics",
    "text": "ü§ñ Machine learning and genomics\nMost machine learning models have applications in population genomics, including dimension reduction, clustering, and supervised classification. While the methods used by consumer genomics companies and researchers are complex and tailored to the complexities of genomic data, we can use ‚Äúoff-the-shelf‚Äù tools from data science and machine learning to understand how more advanced models reach their conclusions.\nRegardless of methods, we face two challenges when analyzing genomic data. First, there‚Äôs typically lots of data, with information on hundreds of peole from thousands of places in the genome. Second, each place in the genome serves as a feature (aka variable) of our analysis. In the previous table there were 5 rows and therefore 5 locations in the genome represented. The full dataset has over 10,000 rows.\n\nGoing the distance with DNA\nHow do you analyze data with 10,000 features, let alone make a plot representing the data? Analysis of such high-dimensinal data typically requires methods to represent the data in a simpler format, a process known as dimension reduction. One of the easiest method of dimension reduction is to calculate distance between each datapoint. In geometry class we learn to use the Pythagorean Formula to calculate the distance between two points on a sheet of paper. If we had a cruel teacher, we may have had to extend the formula to three dimensions. It turns out that ‚Äì while we can‚Äôt necessarily visualize how it works ‚Äì this formula can be extended beyond three dimensions to four, five, or even 10,000. We can similarly extend what we know about the average of a set of numbers and consider the multidimensional mean of a set of data.\nThe table below uses this logic to represent the average genetic distance between indvidiauls in major continental groups in Xing and Jorde‚Äôs dataset. First, the average genetic location of people from each continent is determined, and then the distnance between these mean locations calculate.\nThe largest value in the table is 107 in the Africa-Indigenous Americans rows and columns. The populations of these continents are geographically most distant, and genetically they are, relatively speaking, least similar or ‚Äúmost distant.‚Äù (It is very important add the caveat ‚Äúrelatively‚Äù because two humans are typically 98% the same in terms of DNA, and these numers focus only on the infrequent genetic differenes).\nThe smallest value on the table is 52, between Europe and Asia. These two continents are geographically contiguous with each other and their populations have remained the most genetically similar (least distant) depsite lignuistic and cultural change.\n\n\n\n\n\n\n\n\n\nAfrica\nIndigenous Americans\nAsia\nEurope\n\n\nContinental Group\n\n\n\n\n\n\n\n\nAfrica\n0.0\n107.0\n86.0\n90.0\n\n\nIndigenous Americans\n107.0\n0.0\n63.0\n79.0\n\n\nAsia\n86.0\n63.0\n0.0\n52.0\n\n\nEurope\n90.0\n79.0\n52.0\n0.0\n\n\n\n\n\n\n\nOnce we have characterized the similarities and differences between populations, we can take an individual person‚Äôs DNA sample and compare it to the average locations of each continent. I did this for the DNA sample I introduced at the beginning of this article, and the smallest value is for Europe. This indicats that they are least distant and therefore most similar to the other people in the dataset from this continent.\n\n\n\n\n\n\n\n\n\nDistance\n\n\nContinental Group\n\n\n\n\n\nAfrica\n149.0\n\n\nIndigenous Americans\n143.0\n\n\nAsia\n130.0\n\n\nEurope\n118.0\n\n\n\n\n\n\n\n\n\nA picture is worth 10,000 genome locations\nBecause it has so many features, genomic data cannot be plotted using standard tools like scatterplots. Once we have a table of genetic distances, though, we can make a plot using the results of a process called NMDS (Non-metric Multi-Dimensonal Scaling).\nNMDS turns a distance matrix into a set of x-y coordinates that preserves the relative distances between all sets of points. In the plots\n\n\n\n\n\n\n\n\n\nThere are many machine learning techniques that can be used to visualize high-dimensional genomics data. One of the most common tools used traditionally in population genomics is Principal Components Analysis (PCA). PCA is an unsupervised machine learning method which allows high-dimensonal data to be visualized in 2 or 3 dimensions. PCA scatterplots with 2 dimensions are called biplots, while those with 3 dimensions are triplots.\nIn the case of genomic data, information on individual DNA samples enters into the PCA and the lower dimensional data is then plotted. Dat points represent individuals people in the sample, and the points are color-coded based on the geographic location where the individuals are from. This allows PCA to serve as both a visualization and clustering approach.\nAdditionally, someone whose ancestry is not known or uncertain can have their data transformed by the PCA and plotted along with the other points. The location of the prediction relative to other data points indicates genetic similarity and potentially similar ancestry.\nThe figure below shows data from Xing and Jorde study discussed above after it has been processed through PCA. The data are color-coded by the large-scale geographic areas the samples are derived from. I then took a 23andMe record for a person with unknown ancestry and used my PCA model to estimate which samples from Xing this person is most similar to. Based on their location, they are most likely predominantly European ancestry.\n\n\n\n\n\nPrincipal Components Analysis (PCA) biplot showing the location (X) of a sample with uncertain ancestry. Based on its location, it can be inferred that this person is likely to be of predominantly European ancestry."
  },
  {
    "objectID": "index.html#ancestry-predictions",
    "href": "index.html#ancestry-predictions",
    "title": "Deep Learning about deep ancestry",
    "section": "üìä Ancestry predictions",
    "text": "üìä Ancestry predictions\nPCA biplots are ubiquitous in scientific papers on population genomics and ancestry, often as a central figure. Consumer genetic companies, however, typically focus their results on assignment to one or more ancestry categories. We can carry out a similar assignment, known technically a multi-class classification, using standard tools in Python. In this Analysis, used a Random-forests classifier to gauge the relative probability that the person‚Äô whose DNA sequence we‚Äôve been working with fit into 1 of 7 possible geographic groups."
  },
  {
    "objectID": "index.html#delving-deeper-into-ancestry-and-machine-learning",
    "href": "index.html#delving-deeper-into-ancestry-and-machine-learning",
    "title": "Deep Learning about deep ancestry",
    "section": "Delving deeper into ancestry and machine learning",
    "text": "Delving deeper into ancestry and machine learning\nThe data and analyzes presented in this article should give you a sense for how consumer genomics companies are able to transform a sample of spit or cheek cells into a prediction about someone‚Äôs ancestry. Companies like 23andMe and Ancestry.com now how millions of people in their databases, reference samples from dozens of populations, and machine-learning and deep-learning algorithms tailored to their specific goals. Similar predictions about a person‚Äôs ancestry can be reached using standard machine learning tools. This makes genomic data an excellent place for data scientists explore and test different methods."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to ‚ÄúDeep Learning about deep ancestry‚Äù. This website introduces you to the basics of how DNA sequences and machine learning can be used to characterize someone‚Äôs ancestry. The main landing page of the site contains a high-level overview, while additional sections of the site delve into how genomic data is processed and the machine learning algorithms use.\nThis material is based on material from a course I taught at the University of Pittsburgh and a presentation at PyOhio 2024. The main dataset used is from Xing et al.¬†2010, ‚ÄúToward a more uniform sampling of human genetic diversity: a survey of worldwide populations by high-density genotyping‚Äù.\nIf you have any questions, please contact me at brouwern at gmail.com or message me on LinkedIn.\n\n\n\nPyOhio"
  }
]